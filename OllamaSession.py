import subprocess

class OllamaSession:

    @staticmethod
    def ask(model: str, prompt: str) -> str:
        print(f"Chargement du mod√®le LLM {model} en cours ...")
        try:
            # Ex√©cution du mod√®le via Ollama (local)
            result = subprocess.run(
                ["ollama", "run", model],
                input=prompt,              # ‚ö†Ô∏è envoyer une string, pas des bytes
                capture_output=True,
                text=True,       # important : text=True pour g√©rer str
                encoding="utf-8",          
                timeout=160
            )

            if result.returncode != 0:
                print("‚ùå Erreur Ollama :", result.stderr)
                return "Erreur : impossible d'obtenir une r√©ponse du mod√®le."

            response = result.stdout.strip()

            print("\nüìä Analyse technique g√©n√©r√©e :")
            print(response)

            return response

        except subprocess.TimeoutExpired:
            print("‚è∞ Timeout : le mod√®le a mis trop de temps √† r√©pondre.")
            return "Erreur : d√©lai d√©pass√©."
        except Exception as e:
            print("‚ùå Erreur inattendue :", e)
            return str(e)
